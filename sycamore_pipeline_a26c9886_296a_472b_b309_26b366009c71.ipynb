{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ezazahamad2003/Chico_Hackathon./blob/main/sycamore_pipeline_a26c9886_296a_472b_b309_26b366009c71.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKvsmpIsS0gO"
      },
      "source": [
        "!pip install sycamore-ai[pinecone]\n",
        "# DocPrep code uses the Sycamore document ETL library: https://github.com/aryn-ai/sycamore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM2KAu1AS0gQ"
      },
      "source": [
        "!apt-get install poppler-utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW_Jm-LVS0gR"
      },
      "source": [
        "import pyarrow.fs\n",
        "import sycamore\n",
        "import json\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "from sycamore.functions.tokenizer import OpenAITokenizer\n",
        "from sycamore.llms import OpenAIModels, OpenAI\n",
        "from sycamore.transforms import COALESCE_WHITESPACE\n",
        "from sycamore.transforms.merge_elements import GreedySectionMerger\n",
        "from sycamore.transforms.partition import ArynPartitioner\n",
        "from sycamore.transforms.embed import OpenAIEmbedder\n",
        "from sycamore.materialize_config import MaterializeSourceMode\n",
        "from sycamore.utils.pdf_utils import show_pages\n",
        "from sycamore.transforms.summarize_images import SummarizeImages\n",
        "from sycamore.context import ExecMode\n",
        "from pinecone import ServerlessSpec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QoCjDjRS0gR"
      },
      "source": [
        "# API Keys\n",
        "from google.colab import userdata\n",
        "# Set your secrets in the colab notebook. Navigate to the left pane\n",
        "# and choose the key option to set your keys. Make sure to enable Notebook access\n",
        "try:\n",
        "  # Visit https://www.aryn.ai/get-started to get a key.\n",
        "  os.environ[\"ARYN_API_KEY\"] = userdata.get('ARYN_API_KEY')\n",
        "  os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except Exception as e:\n",
        "  print(\"YOU ARE MISSING REQUIRED API KEYS FOR THIS PIPELINE. Add your API keys to the Secrets page (icon is a key) in the Colab left navigation panel. It is case sensitive.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMqRNEYRS0gS"
      },
      "source": [
        "# Sycamore uses lazy execution for efficiency, so the ETL pipeline will only execute when running cells with specific functions.\n",
        "\n",
        "paths = [\"\"C:\\Users\\ezaza\\Downloads\\Digestive_System_508-bbox.json\"\"]\n",
        "\n",
        "# Initialize the Sycamore context\n",
        "ctx = sycamore.init(ExecMode.LOCAL)\n",
        "# Set the embedding model and its parameters\n",
        "model_name = \"text-embedding-3-small\"\n",
        "max_tokens = 8191\n",
        "dimensions = 1536\n",
        "# Initialize the tokenizer\n",
        "tokenizer = OpenAITokenizer(model_name)\n",
        "\n",
        "ds = (\n",
        "    ctx.read.binary(paths, binary_format=\"pdf\")\n",
        "    # Partition and extract tables and images\n",
        "    .partition(partitioner=ArynPartitioner(\n",
        "        threshold=\"auto\",\n",
        "        use_ocr=True,\n",
        "        extract_table_structure=True,\n",
        "        extract_images=True,\n",
        "        source=\"docprep\"\n",
        "    ))\n",
        "    # Use materialize to cache output. If changing upstream code or input files, change setting from USE_STORED to RECOMPUTE to create a new cache.\n",
        "    .materialize(path=\"/content/materialize/partitioned\", source_mode=MaterializeSourceMode.USE_STORED)\n",
        "    # Merge elements into larger chunks\n",
        "    .merge(merger=GreedySectionMerger(\n",
        "      tokenizer=tokenizer,  max_tokens=max_tokens, merge_across_pages=False\n",
        "    ))\n",
        "    # Split elements that are too big to embed\n",
        "    .split_elements(tokenizer=tokenizer, max_tokens=max_tokens)\n",
        ")\n",
        "\n",
        "ds.execute()\n",
        "\n",
        "# Display the first 3 pages after chunking\n",
        "show_pages(ds, limit=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61fTsXvfS0gS"
      },
      "source": [
        "embedded_ds = (\n",
        "    # Copy document properties to each Document's sub-elements\n",
        "    ds.spread_properties([\"path\", \"entity\"])\n",
        "    # Convert all Elements to Documents\n",
        "    .explode()\n",
        "    # Embed each Document. You can change the embedding model. Make your target vector index matches this number of dimensions.\n",
        "    .embed(embedder=OpenAIEmbedder(model_name=model_name))\n",
        ")\n",
        "# To know more about docset transforms, please visit https://sycamore.readthedocs.io/en/latest/sycamore/transforms.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROKy7acS0gS"
      },
      "source": [
        "# Create an instance of ServerlessSpec with the specified cloud provider and region\n",
        "spec = ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "index_name = \"quickstart\"\n",
        "# Write data to a Pinecone index\n",
        "embedded_ds.write.pinecone(index_name=index_name,\n",
        "    dimensions=dimensions,\n",
        "    distance_metric=\"cosine\",\n",
        "    index_spec=spec\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahA5bU5gS0gT"
      },
      "source": [
        "# Verify data has been loaded using DocSet Query to retrieve chunks\n",
        "query_docs = ctx.read.pinecone(index_name=index_name, api_key=os.getenv('PINECONE_API_KEY'))\n",
        "query_docs.show(show_embedding=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}